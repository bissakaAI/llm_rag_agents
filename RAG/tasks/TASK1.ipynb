{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e29ec4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_by_sentences(text, max_chunk_size=500):\n",
    "    \"\"\"\n",
    "    Split text into chunks by sentences, keeping sentences intact.\n",
    "    \n",
    "    Args:\n",
    "        text: The text to chunk\n",
    "        max_chunk_size: Maximum characters per chunk\n",
    "    \n",
    "    Returns:\n",
    "        List of text chunks\n",
    "    \"\"\"\n",
    "    # Simple sentence splitting (split on . ! ?)\n",
    "    import re\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    \n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        # Check if adding this sentence would exceed max size\n",
    "        if len(current_chunk) + len(sentence) > max_chunk_size and current_chunk:\n",
    "            # Save current chunk and start new one\n",
    "            chunks.append(current_chunk.strip())\n",
    "            current_chunk = sentence\n",
    "        else:\n",
    "            # Add sentence to current chunk\n",
    "            current_chunk += \" \" + sentence if current_chunk else sentence\n",
    "    \n",
    "    # Don't forget the last chunk\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# Test it\n",
    "chunks = chunk_by_sentences(sample_document, max_chunk_size=400)\n",
    "\n",
    "print(f\"Number of chunks: {len(chunks)}\\n\")\n",
    "for i, chunk in enumerate(chunks, 1):\n",
    "    print(f\"Chunk {i} ({len(chunk)} chars):\")\n",
    "    print(chunk)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc15193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_by_paragraphs(text, min_chunk_size=100):\n",
    "    \"\"\"\n",
    "    Split text by paragraphs (double newlines).\n",
    "    \n",
    "    Args:\n",
    "        text: The text to chunk\n",
    "        min_chunk_size: Minimum characters per chunk (combine small paragraphs)\n",
    "    \n",
    "    Returns:\n",
    "        List of text chunks\n",
    "    \"\"\"\n",
    "    # Split by double newlines (paragraph separator)\n",
    "    paragraphs = text.split('\\n\\n')\n",
    "    \n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    \n",
    "    for para in paragraphs:\n",
    "        para = para.strip()\n",
    "        if not para:\n",
    "            continue\n",
    "            \n",
    "        # If paragraph is too small, combine with next\n",
    "        if len(para) < min_chunk_size:\n",
    "            current_chunk += \"\\n\\n\" + para if current_chunk else para\n",
    "        else:\n",
    "            # Save previous chunk if exists\n",
    "            if current_chunk:\n",
    "                chunks.append(current_chunk.strip())\n",
    "            # Start new chunk with this paragraph\n",
    "            current_chunk = para\n",
    "    \n",
    "    # Don't forget the last chunk\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# Test it\n",
    "chunks = chunk_by_paragraphs(sample_document, min_chunk_size=100)\n",
    "\n",
    "print(f\"Number of chunks: {len(chunks)}\\n\")\n",
    "for i, chunk in enumerate(chunks, 1):\n",
    "    print(f\"Chunk {i} ({len(chunk)} chars):\")\n",
    "    print(chunk)\n",
    "    print(\"-\" * 80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
