{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a6eeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from langgraph.graph import START, END, StateGraph, MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import ToolNode, create_react_agent\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "from typing import Literal, TypedDict, Annotated\n",
    "import operator\n",
    "import os\n",
    "\n",
    "print(\"âœ… All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d91e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Optional\n",
    "\n",
    "class HybridAgentState(TypedDict):\n",
    "    # Core task\n",
    "    task: str\n",
    "\n",
    "    # -------- Plan-Execute --------\n",
    "    plan: List[str]\n",
    "    current_step: int\n",
    "    step_results: List[str]\n",
    "\n",
    "    # -------- Generation --------\n",
    "    draft: str\n",
    "\n",
    "    # -------- Reflection --------\n",
    "    critique: str\n",
    "    iterations: int\n",
    "\n",
    "    # -------- Final --------\n",
    "    final_output: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4b561b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def planner(state: HybridAgentState) -> dict:\n",
    "    prompt = f\"\"\"\n",
    "    Break the following task into clear, ordered steps.\n",
    "\n",
    "    Task:\n",
    "    {state['task']}\n",
    "\n",
    "    Return the steps as a numbered list.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\nðŸ§  PLANNER: Creating plan...\")\n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "\n",
    "    plan = [\n",
    "        line.strip(\"0123456789. \")\n",
    "        for line in response.content.splitlines()\n",
    "        if line.strip()\n",
    "    ]\n",
    "\n",
    "    print(\"ðŸ“‹ PLAN:\")\n",
    "    for i, step in enumerate(plan, 1):\n",
    "        print(f\"  Step {i}: {step}\")\n",
    "\n",
    "    return {\n",
    "        \"plan\": plan,\n",
    "        \"current_step\": 0,\n",
    "        \"step_results\": []\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1c3583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def executor(state: HybridAgentState) -> dict:\n",
    "    step_idx = state[\"current_step\"]\n",
    "    step = state[\"plan\"][step_idx]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Execute the following step carefully and return the result.\n",
    "\n",
    "    Step:\n",
    "    {step}\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"\\nâš™ï¸ EXECUTOR: Running step {step_idx + 1}\")\n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "\n",
    "    result = response.content\n",
    "\n",
    "    print(f\"âœ… Result of step {step_idx + 1}:\\n{result[:150]}...\\n\")\n",
    "\n",
    "    return {\n",
    "        \"current_step\": step_idx + 1,\n",
    "        \"step_results\": state[\"step_results\"] + [result]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69564019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "def should_continue_execution(\n",
    "    state: HybridAgentState\n",
    ") -> Literal[\"executor\", \"generator\"]:\n",
    "\n",
    "    if state[\"current_step\"] < len(state[\"plan\"]):\n",
    "        return \"executor\"\n",
    "\n",
    "    print(\"ðŸ All execution steps completed\\n\")\n",
    "    return \"generator\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4f3a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(state: HybridAgentState) -> dict:\n",
    "    combined_results = \"\\n\\n\".join(state[\"step_results\"])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Using the information below, create a complete response to the task.\n",
    "\n",
    "    Task:\n",
    "    {state['task']}\n",
    "\n",
    "    Collected Information:\n",
    "    {combined_results}\n",
    "\n",
    "    Create a clear and coherent draft.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"âœï¸ GENERATOR: Creating initial draft...\")\n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "\n",
    "    print(\"\\nðŸ“ INITIAL DRAFT:\\n\")\n",
    "    print(response.content)\n",
    "\n",
    "    return {\"draft\": response.content}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883664be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def critic(state: HybridAgentState) -> dict:\n",
    "    prompt = f\"\"\"\n",
    "    Critique the following response.\n",
    "\n",
    "    Task:\n",
    "    {state['task']}\n",
    "\n",
    "    Response:\n",
    "    {state['draft']}\n",
    "\n",
    "    Focus on:\n",
    "    - Beginner-friendliness\n",
    "    - Clarity\n",
    "    - Completeness\n",
    "\n",
    "    If excellent, say \"APPROVED: reason\".\n",
    "    Otherwise, explain what needs improvement.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\nðŸ” CRITIC: Evaluating draft...\")\n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "\n",
    "    print(\"\\nðŸ§ª CRITIQUE:\\n\")\n",
    "    print(response.content)\n",
    "\n",
    "    return {\n",
    "        \"critique\": response.content,\n",
    "        \"iterations\": state[\"iterations\"] + 1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4aab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_REFLECTIONS = 2\n",
    "\n",
    "def refiner(state: HybridAgentState) -> dict:\n",
    "    prompt = f\"\"\"\n",
    "    Improve the response based on the critique.\n",
    "\n",
    "    Task:\n",
    "    {state['task']}\n",
    "\n",
    "    Current Draft:\n",
    "    {state['draft']}\n",
    "\n",
    "    Critique:\n",
    "    {state['critique']}\n",
    "\n",
    "    Produce a refined, beginner-friendly version.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"\\nðŸ” REFINER: Refining (iteration {state['iterations']})...\")\n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "\n",
    "    print(\"\\nâœ¨ REFINED DRAFT:\\n\")\n",
    "    print(response.content)\n",
    "\n",
    "    return {\"draft\": response.content}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323e7e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_refine_again(\n",
    "    state: HybridAgentState\n",
    ") -> Literal[\"refiner\", \"finalizer\"]:\n",
    "\n",
    "    if \"APPROVED\" in state[\"critique\"].upper():\n",
    "        print(\"âœ… Draft approved\")\n",
    "        return \"finalizer\"\n",
    "\n",
    "    if state[\"iterations\"] >= MAX_REFLECTIONS:\n",
    "        print(\"âš ï¸ Max reflection iterations reached\")\n",
    "        return \"finalizer\"\n",
    "\n",
    "    return \"refiner\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d146a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalizer(state: HybridAgentState) -> dict:\n",
    "    print(\"\\nðŸŽ‰ FINAL OUTPUT READY\\n\")\n",
    "    return {\"final_output\": state[\"draft\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd04932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "builder = StateGraph(HybridAgentState)\n",
    "\n",
    "builder.add_node(\"planner\", planner)\n",
    "builder.add_node(\"executor\", executor)\n",
    "builder.add_node(\"generator\", generator)\n",
    "builder.add_node(\"critic\", critic)\n",
    "builder.add_node(\"refiner\", refiner)\n",
    "builder.add_node(\"finalizer\", finalizer)\n",
    "\n",
    "builder.add_edge(START, \"planner\")\n",
    "builder.add_edge(\"planner\", \"executor\")\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    \"executor\",\n",
    "    should_continue_execution,\n",
    "    {\n",
    "        \"executor\": \"executor\",\n",
    "        \"generator\": \"generator\"\n",
    "    }\n",
    ")\n",
    "\n",
    "builder.add_edge(\"generator\", \"critic\")\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    \"critic\",\n",
    "    should_refine_again,\n",
    "    {\n",
    "        \"refiner\": \"refiner\",\n",
    "        \"finalizer\": \"finalizer\"\n",
    "    }\n",
    ")\n",
    "\n",
    "builder.add_edge(\"refiner\", \"critic\")\n",
    "builder.add_edge(\"finalizer\", END)\n",
    "\n",
    "hybrid_agent = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cb9bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = hybrid_agent.invoke({\n",
    "    \"task\": \"Research the benefits of Python programming, create a summary, and make it beginner-friendly\",\n",
    "    \"plan\": [],\n",
    "    \"current_step\": 0,\n",
    "    \"step_results\": [],\n",
    "    \"draft\": \"\",\n",
    "    \"critique\": \"\",\n",
    "    \"iterations\": 0,\n",
    "    \"final_output\": \"\"\n",
    "})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
