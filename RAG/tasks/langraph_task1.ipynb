{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de918eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, StateGraph, MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage,ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "from typing import Literal\n",
    "import os\n",
    "\n",
    "print(\"✅ All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f364d0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"openai_key\")\n",
    "\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found! Please set it in your .env file.\")\n",
    "\n",
    "print(\"✅ API key loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdefe3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.5,\n",
    "    api_key=openai_api_key\n",
    ")\n",
    "\n",
    "print(f\"✅ LLM initialized: {llm.model_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415e9b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#system prompt that defines assistant behavior \n",
    "\n",
    "sys_msg= SystemMessage(\n",
    "    content=\"You are a friendly assistant but answers user question.Be careful and concise.\"\n",
    ")\n",
    "def assistant(state:MessagesState)-> dict:\n",
    "    \"\"\"\n",
    "    The assistant node - processes messages and generates response.\n",
    "    \"\"\"\n",
    "\n",
    "    # combine system prompt with conversation history\n",
    "    messages=[sys_msg] + state[\"messages\"]\n",
    "\n",
    "    # Get response from LLM\n",
    "    response=llm.invoke(messages)\n",
    "\n",
    "    # Return as state update\n",
    "    return {\"messages\": [AIMessage(content=response.content)]}\n",
    "\n",
    "print(\"✅ Assistant node defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3b2ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a stategraph with messagesState\n",
    "\n",
    "builder= StateGraph(MessagesState)\n",
    "\n",
    "#Add the assistant mode\n",
    "builder.add_node(\"assistant\",assistant)\n",
    "\n",
    "#define the flow \n",
    "# START → assistant → END\n",
    "builder.add_edge(START,\"assistant\")\n",
    "builder.add_edge(\"assistant\",END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ba2ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a memory checkpointer (stores in memory)\n",
    "memory=MemorySaver()\n",
    "\n",
    "#compile the graph with memory\n",
    "agent=builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce90ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_chat():\n",
    "    \"\"\"\n",
    "    Run an interactive chat session.\n",
    "    Type 'exit' or 'quit' to stop.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Interactive Chat Started\")\n",
    "    print(\"Type your message and press Enter. Type 'exit' to quit.\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "    thread_id = \"interactive_session2\"\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"\\nYou: \").strip()\n",
    "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "            print(\"\\nGoodbye...\")\n",
    "            break\n",
    "        \n",
    "        if not user_input:\n",
    "            continue\n",
    "        \n",
    "        #Get response\n",
    "        result = agent.invoke(\n",
    "            {\"messages\": [HumanMessage(content=user_input)]},\n",
    "            config={\"configurable\": {\"thread_id\": thread_id}}\n",
    "        )\n",
    "\n",
    "        # Print response\n",
    "        agent_message = result[\"messages\"][-1]\n",
    "        user_message = result['messages'][-2]\n",
    "        print(f\"\\nYou: {user_message.content}\")\n",
    "        print(f\"\\nAgent: {agent_message.content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aa9f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_chat()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
