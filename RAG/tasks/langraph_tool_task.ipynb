{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aef16d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\Working_with_LLMS\\llmvenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All imports successful\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import START, END, StateGraph, MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage,ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "from typing import Literal\n",
    "import os\n",
    "\n",
    "print(\"âœ… All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3db2a325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… API key loaded\n"
     ]
    }
   ],
   "source": [
    "# Load API key\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"openai_key\")\n",
    "\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found! Please set it in your .env file.\")\n",
    "\n",
    "print(\"âœ… API key loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba2ae126",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Returns simulated weather for a given city.\"\"\"\n",
    "    fake_weather = {\n",
    "        \"lagos\": \"Sunny, 30Â°C\",\n",
    "        \"london\": \"Cloudy, 18Â°C\",\n",
    "        \"new york\": \"Rainy, 22Â°C\"\n",
    "    }\n",
    "    return fake_weather.get(city.lower(), \"Weather data not available.\")\n",
    "\n",
    "\n",
    "@tool\n",
    "def define_word(word: str) -> str:\n",
    "    \"\"\"Returns the definition of a word.\"\"\"\n",
    "    dictionary = {\n",
    "        \"ephemeral\": \"Lasting for a very short time.\",\n",
    "        \"ubiquitous\": \"Present, appearing, or found everywhere.\",\n",
    "        \"resilient\": \"Able to recover quickly from difficulties.\"\n",
    "    }\n",
    "    return dictionary.get(word.lower(), \"Definition not found.\")\n",
    "\n",
    "\n",
    "@tool\n",
    "def web_search(query: str) -> str:\n",
    "    \"\"\"Search the web using DuckDuckGo.\"\"\"\n",
    "    with DDGS() as ddgs:\n",
    "        results = ddgs.text(query, max_results=3)\n",
    "        return \"\\n\".join(r[\"body\"] for r in results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "764fa6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Conditional routing function defined\n"
     ]
    }
   ],
   "source": [
    "def should_continue(state: MessagesState) -> Literal[\"tools\", \"__end__\"]:\n",
    "    \"\"\"\n",
    "    Decide next step based on last message.\n",
    "    \n",
    "    If LLM called a tool â†’ go to 'tools' node\n",
    "    If LLM provided final answer â†’ go to END\n",
    "    \"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    \n",
    "    # Check if LLM made tool calls\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    \n",
    "    # No tool calls - we're done\n",
    "    return \"__end__\"\n",
    "\n",
    "print(\"âœ… Conditional routing function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1d96cb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Assistant node defined\n"
     ]
    }
   ],
   "source": [
    "#system prompt that defines assistant behavior \n",
    "\n",
    "sys_msg= SystemMessage(\n",
    "    content=\"\"\"You are a friendly assistant with access to helpful tools\n",
    "    when asked questions related to weather use the weather tool and provide answers from the hard coded answers in  the tool.\n",
    "    when asked questions related to word definitions use the define_word tool and provide answers from the hard coded answers in  the tool.\n",
    "    when asked general questions use the web_search tool\n",
    "    Always provide concise and accurate responses.\n",
    "    Only use tools when necessary - for simple questions, answer directly.\"\"\")\n",
    "def assistant(state:MessagesState)-> dict:\n",
    "    \"\"\"\n",
    "    The assistant node - processes messages and generates response.\n",
    "    \"\"\"\n",
    "\n",
    "    # combine system prompt with conversation history\n",
    "    messages=[sys_msg] + state[\"messages\"]\n",
    "\n",
    "    # Get response from LLM\n",
    "    response=llm.invoke(messages)\n",
    "\n",
    "    # Return as state update\n",
    "    return {\"messages\": [AIMessage(content=response.content)]}\n",
    "\n",
    "print(\"âœ… Assistant node defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "864749c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LLM initialized: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "# Initialize LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,  # Lower temperature for more precise tool usage\n",
    "    api_key=openai_api_key\n",
    ")\n",
    "\n",
    "print(f\"âœ… LLM initialized: {llm.model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "88114530",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tools = [get_weather, define_word, web_search]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "01238d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] LangGraph agent ready!\n"
     ]
    }
   ],
   "source": [
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tool\", ToolNode(tools))\n",
    "\n",
    "builder.set_entry_point(\"assistant\")\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tool\": \"tool\",\n",
    "        \"__end__\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "builder.add_edge(\"tool\", \"assistant\")\n",
    "\n",
    "# app = builder.compile()\n",
    "\n",
    "print(\"[OK] LangGraph agent ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ae644066",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a memory checkpointer (stores in memory)\n",
    "memory=MemorySaver()\n",
    "\n",
    "#compile the graph with memory\n",
    "agent=builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b87edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_agent(query: str,thread_id: str = \"test_session\"):\n",
    "#     result = agent.invoke(\n",
    "#         {\"messages\": [HumanMessage(content=query)]}, config={\"configurable\": {\"thread_id\": thread_id}}\n",
    "#     )\n",
    "#     return result[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0b2f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I can check the current weather for you. Please hold on for a moment.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # First query\n",
    "# run_agent(\"what is the weather in lagos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "26867a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Test function ready\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Helper function\n",
    "def run_agent(user_input: str, thread_id: str = \"test_session\"):\n",
    "    \"\"\"\n",
    "    Run the agent and display the conversation.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ðŸ‘¤ User: {user_input}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    result = agent.invoke(\n",
    "        {\"messages\": [HumanMessage(content=user_input)]},\n",
    "        config={\"configurable\": {\"thread_id\": thread_id}}\n",
    "    )\n",
    "    \n",
    "    for message in result[\"messages\"]:\n",
    "        if isinstance(message, HumanMessage):\n",
    "            continue  # Already printed\n",
    "        elif isinstance(message, AIMessage):\n",
    "            if message.tool_calls:\n",
    "                return result[\"messages\"][-1].content\n",
    "                print(f\"ðŸ¤– Agent: [Calling tool: {message.tool_calls[0]['name']}]\")\n",
    "            else:\n",
    "                print(f\"ðŸ¤– Agent: {message.content}\")\n",
    "        elif isinstance(message, ToolMessage):\n",
    "            print(f\"ðŸ”§ Tool Result: {message.content[:100]}...\" if len(message.content) > 100 else f\"ðŸ”§ Tool Result: {message.content}\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\\n\")\n",
    "\n",
    "print(\"âœ… Test function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4fa01ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ‘¤ User: what is the weather in lagos\n",
      "======================================================================\n",
      "\n",
      "ðŸ¤– Agent: I can check the current weather for you. Please hold on for a moment.\n",
      "ðŸ¤– Agent: The current weather in Lagos is 28Â°C with scattered clouds. The humidity is at 78%, and there is a light breeze coming from the east at 10 km/h.\n",
      "ðŸ¤– Agent: The current weather in Lagos is 28Â°C with scattered clouds. The humidity is at 78%, and there is a light breeze coming from the east at 10 km/h.\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First query\n",
    "run_agent(\"what is the weather in lagos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "88aba570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ‘¤ User: what does resilient mean\n",
      "======================================================================\n",
      "\n",
      "ðŸ¤– Agent: I can check the current weather for you. Please hold on for a moment.\n",
      "ðŸ¤– Agent: The current weather in Lagos is 28Â°C with scattered clouds. The humidity is at 78%, and there is a light breeze coming from the east at 10 km/h.\n",
      "ðŸ¤– Agent: The current weather in Lagos is 28Â°C with scattered clouds. The humidity is at 78%, and there is a light breeze coming from the east at 10 km/h.\n",
      "ðŸ¤– Agent: The word \"resilient\" means able to withstand or recover quickly from difficult conditions. It often refers to the ability to bounce back from adversity, challenges, or setbacks.\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First query\n",
    "run_agent(\"what does resilient mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4bc29dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ‘¤ User: who is the current president of iraq\n",
      "======================================================================\n",
      "\n",
      "ðŸ¤– Agent: I can check the current weather for you. Please hold on for a moment.\n",
      "ðŸ¤– Agent: The current weather in Lagos is 28Â°C with scattered clouds. The humidity is at 78%, and there is a light breeze coming from the east at 10 km/h.\n",
      "ðŸ¤– Agent: The current weather in Lagos is 28Â°C with scattered clouds. The humidity is at 78%, and there is a light breeze coming from the east at 10 km/h.\n",
      "ðŸ¤– Agent: The word \"resilient\" means able to withstand or recover quickly from difficult conditions. It often refers to the ability to bounce back from adversity, challenges, or setbacks.\n",
      "ðŸ¤– Agent: The current president of Iraq is Abdul Latif Rashid. He took office on October 13, 2022.\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First query\n",
    "run_agent(\"who is the current president of iraq\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
