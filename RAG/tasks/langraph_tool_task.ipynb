{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aef16d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, StateGraph, MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage,ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "from typing import Literal\n",
    "import os\n",
    "\n",
    "print(\"✅ All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2ae126",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Returns simulated weather for a given city.\"\"\"\n",
    "    fake_weather = {\n",
    "        \"lagos\": \"Sunny, 30°C\",\n",
    "        \"london\": \"Cloudy, 18°C\",\n",
    "        \"new york\": \"Rainy, 22°C\"\n",
    "    }\n",
    "    return fake_weather.get(city.lower(), \"Weather data not available.\")\n",
    "\n",
    "\n",
    "@tool\n",
    "def define_word(word: str) -> str:\n",
    "    \"\"\"Returns the definition of a word.\"\"\"\n",
    "    dictionary = {\n",
    "        \"ephemeral\": \"Lasting for a very short time.\",\n",
    "        \"ubiquitous\": \"Present, appearing, or found everywhere.\",\n",
    "        \"resilient\": \"Able to recover quickly from difficulties.\"\n",
    "    }\n",
    "    return dictionary.get(word.lower(), \"Definition not found.\")\n",
    "\n",
    "\n",
    "@tool\n",
    "def web_search(query: str) -> str:\n",
    "    \"\"\"Search the web using DuckDuckGo.\"\"\"\n",
    "    with DDGS() as ddgs:\n",
    "        results = ddgs.text(query, max_results=3)\n",
    "        return \"\\n\".join(r[\"body\"] for r in results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d96cb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#system prompt that defines assistant behavior \n",
    "\n",
    "sys_msg= SystemMessage(\n",
    "    content=\"You are a friendly assistant but answers user question.Be careful and concise.\"\n",
    ")\n",
    "def assistant(state:MessagesState)-> dict:\n",
    "    \"\"\"\n",
    "    The assistant node - processes messages and generates response.\n",
    "    \"\"\"\n",
    "\n",
    "    # combine system prompt with conversation history\n",
    "    messages=[sys_msg] + state[\"messages\"]\n",
    "\n",
    "    # Get response from LLM\n",
    "    response=llm.invoke(messages)\n",
    "\n",
    "    # Return as state update\n",
    "    return {\"messages\": [AIMessage(content=response.content)]}\n",
    "\n",
    "print(\"✅ Assistant node defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88114530",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "tools = [get_weather, define_word, web_search]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01238d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(AgentState)\n",
    "\n",
    "builder.add_node(\"agent\", agent_node)\n",
    "builder.add_node(\"tool\", tool_node)\n",
    "\n",
    "builder.set_entry_point(\"agent\")\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_use_tool,\n",
    "    {\n",
    "        \"tool\": \"tool\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "\n",
    "builder.add_edge(\"tool\", \"agent\")\n",
    "\n",
    "app = builder.compile()\n",
    "\n",
    "print(\"[OK] LangGraph agent ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae644066",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a memory checkpointer (stores in memory)\n",
    "memory=MemorySaver()\n",
    "\n",
    "#compile the graph with memory\n",
    "agent=builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26867a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent(query: str):\n",
    "    result = app.invoke(\n",
    "        {\"messages\": [HumanMessage(content=query)]}\n",
    "    )\n",
    "    return result[\"messages\"][-1].content\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
