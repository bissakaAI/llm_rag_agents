{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6013ce1",
   "metadata": {},
   "source": [
    "This notebook implements a complete **Agentic RAG system using LangGraph** for the **Supply Chain** domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d11d2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langgraph.graph import START, END, StateGraph, MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "from langchain.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from typing import Literal\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfa96fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"paid_api\")\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"API key not found in .env\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-5-nano\",\n",
    "    temperature=0.4,\n",
    "    api_key=API_KEY\n",
    ")\n",
    "\n",
    "print(\"LLM initialized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42e9923",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load Supply Chain documents (PDFs)\n",
    "DOC_PATH = r\"C:\\Users\\owner\\Desktop\\Agentic_RAG_SupplyChain_KB\"\n",
    "\n",
    "loader = PyPDFDirectoryLoader(DOC_PATH)\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c5b9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Chunk documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=75\n",
    ")\n",
    "\n",
    "doc_chunks = text_splitter.split_documents(documents)\n",
    "print(f\"Created {len(doc_chunks)} chunks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47399f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create vector store\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    api_key=API_KEY\n",
    ")\n",
    "\n",
    "VECTOR_DB_PATH = \"./chroma_supplychain_rag\"\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"supplychain_docs\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=VECTOR_DB_PATH\n",
    ")\n",
    "\n",
    "vectorstore.add_documents(doc_chunks)\n",
    "print(\"Vector store ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c086b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tool\n",
    "def retrieve_supplychain_docs(query: str) -> str:\n",
    "    \"\"\"Retrieve supply chain documents for domain-specific questions.\"\"\"\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=\"mmr\",\n",
    "        search_kwargs={\"k\": 5, \"fetch_k\": 12}\n",
    "    )\n",
    "    docs = retriever.invoke(query)\n",
    "\n",
    "    if not docs:\n",
    "        return \"No relevant documents found.\"\n",
    "\n",
    "    return \"\\n\\n---\\n\\n\".join(\n",
    "        f\"Source {i+1}:\\n{doc.page_content}\"\n",
    "        for i, doc in enumerate(docs)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac5a6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "system_prompt = SystemMessage(content=\"\"\"\n",
    "You are SupplyChainBot, an expert assistant in Supply Chain Management.\n",
    "\n",
    "Retrieve documents only when supply-chain-specific knowledge is required.\n",
    "Do NOT retrieve for greetings, math, dates, or general knowledge.\n",
    "Cite retrieved information clearly.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fdeb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tools = [retrieve_supplychain_docs]\n",
    "llm_with_tools = llm.bind_tools(tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6895250",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def assistant(state: MessagesState) -> dict:\n",
    "    messages = [system_prompt] + state[\"messages\"]\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def should_continue(state: MessagesState) -> Literal[\"tools\", \"__end__\"]:\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return \"__end__\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b4df33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    should_continue,\n",
    "    {\"tools\": \"tools\", \"__end__\": END}\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "agent = builder.compile(checkpointer=memory)\n",
    "\n",
    "print(\"Agentic RAG compiled\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdff33b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def query_agent(queries, thread_id=\"test\"):\n",
    "    for q in queries:\n",
    "        print(\"=\" * 70)\n",
    "        print(\"Query:\", q)\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "        result = agent.invoke(\n",
    "            {\"messages\": [HumanMessage(content=q)]},\n",
    "            config={\"configurable\": {\"thread_id\": thread_id}}\n",
    "        )\n",
    "\n",
    "        used_retrieval = any(\n",
    "            isinstance(m, AIMessage) and m.tool_calls\n",
    "            for m in result[\"messages\"]\n",
    "        )\n",
    "\n",
    "        print(\"Answer:\", result[\"messages\"][-1].content)\n",
    "        print(\"Decision:\", \"RETRIEVED\" if used_retrieval else \"ANSWERED DIRECTLY\")\n",
    "        print()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
