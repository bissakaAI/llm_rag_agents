{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37c2caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_openai import (\n",
    "    setup_openai_api, create_embeddings, create_llm,\n",
    "    load_msme_data, create_vectorstore, get_baseline_prompt\n",
    ")\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.load import dumps, loads\n",
    "\n",
    "print(\"[OK] Imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97803ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = setup_openai_api()\n",
    "embeddings = create_embeddings(api_key)\n",
    "llm = create_llm(api_key)\n",
    "documents, metadatas, ids = load_msme_data(\"msme.csv\")\n",
    "\n",
    "vectorstore = create_vectorstore(\n",
    "    documents, metadatas, ids, embeddings,\n",
    "    collection_name=\"msme_technique2\",\n",
    "    persist_directory=\"./chroma_db_technique2\"\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "print(\"[OK] Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dacb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_gen_template = \"\"\"You are an AI assistant helping to improve search results.\n",
    "Your task is to generate 4 different versions of the given user question.\n",
    "\n",
    "These variations should:\n",
    "- Rephrase using different words\n",
    "- Use different levels of specificity\n",
    "- Include relevant synonyms\n",
    "- Maintain the original intent\n",
    "\n",
    "Provide ONLY the questions, one per line, without numbering or explanation.\n",
    "\n",
    "Original question: {question}\n",
    "\n",
    "Alternative questions:\"\"\"\n",
    "\n",
    "query_gen_prompt = ChatPromptTemplate.from_template(query_gen_template)\n",
    "print(\"[OK] Query generation prompt ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5dd194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain that generates multiple queries\n",
    "query_generator = (\n",
    "    query_gen_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "    | (lambda x: [q.strip() for q in x.split('\\n') if q.strip()])\n",
    ")\n",
    "\n",
    "print(\"[OK] Query generator chain created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b05a6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_docs(documents):\n",
    "    \"\"\"Remove duplicate documents using content hashing\"\"\"\n",
    "    unique_docs = list(set(dumps(doc) for doc in documents))\n",
    "    return [loads(doc) for doc in unique_docs]\n",
    "\n",
    "print(\"[OK] Deduplication function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6878ed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete chain:\n",
    "# 1. Generate multiple queries\n",
    "# 2. Retrieve docs for each query (map)\n",
    "# 3. Deduplicate\n",
    "# 4. Pass to prompt with original question\n",
    "\n",
    "multi_query_retrieval = (\n",
    "    query_generator\n",
    "    | retriever.map()  # Retrieve for each generated query\n",
    "    | get_unique_docs  # Remove duplicates\n",
    ")\n",
    "\n",
    "prompt = get_baseline_prompt()\n",
    "\n",
    "multi_query_rag_chain = (\n",
    "    {\"context\": multi_query_retrieval, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"[OK] Multi-query RAG chain ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23186a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Baseline RAG (single query)\n",
    "# ----------------------------\n",
    "\n",
    "baseline_rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"[OK] Baseline RAG chain ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c05e1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries = [\n",
    "    \"business money\",\n",
    "    \"company rules\",\n",
    "    \"get funding\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc6fe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in test_queries:\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"USER QUERY: {query}\\n\")\n",
    "\n",
    "    print(\"ðŸ”¹ BASELINE RAG RESPONSE:\")\n",
    "    baseline_response = baseline_rag_chain.invoke(query)\n",
    "    print(baseline_response)\n",
    "\n",
    "    print(\"\\nðŸ”¹ MULTI-QUERY RAG RESPONSE:\")\n",
    "    multi_query_response = multi_query_rag_chain.invoke(query)\n",
    "    print(multi_query_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7412a75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in test_queries:\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"ORIGINAL QUERY: {query}\")\n",
    "    generated_queries = query_generator.invoke({\"question\": query})\n",
    "\n",
    "    print(\"Generated query variations:\")\n",
    "    for q in generated_queries:\n",
    "        print(f\"- {q}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
