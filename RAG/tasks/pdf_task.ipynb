{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a7d896d",
   "metadata": {},
   "source": [
    "# i am to create a vector database that helps chumk a pdf file and retrive from the vector database "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7900f4eb",
   "metadata": {},
   "source": [
    "## I will be using faiss  then chromma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e9e070",
   "metadata": {},
   "source": [
    "## Using chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8bbcf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "#use sentence-transformer embedding function \n",
    "sentence_trans_embeding_func= embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97f8d720",
   "metadata": {},
   "outputs": [],
   "source": [
    "client= chromadb.PersistentClient(\"./chroma_db\")\n",
    "\n",
    "# collection= client.get_or_create_collection(name=\"python_for_dummies_collection\",metadata={\"category\":\"Programming\"},embedding_function=sentence_trans_embeding_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af2cd804",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection= client.get_collection(name=\"python_for_dummies_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d3d4dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python_for_dummies_collection'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49d25d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_by_sentences(text, max_chunk_size=500):\n",
    "    \"\"\"\n",
    "    Split text into chunks by sentences, keeping sentences intact.\n",
    "    \n",
    "    Args:\n",
    "        text: The text to chunk\n",
    "        max_chunk_size: Maximum characters per chunk\n",
    "    \n",
    "    Returns:\n",
    "        List of text chunks\n",
    "    \"\"\"\n",
    "    # Simple sentence splitting (split on . ! ?)\n",
    "    import re\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    \n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        # Check if adding this sentence would exceed max size\n",
    "        if len(current_chunk) + len(sentence) > max_chunk_size and current_chunk:\n",
    "            # Save current chunk and start new one\n",
    "            chunks.append(current_chunk.strip())\n",
    "            current_chunk = sentence\n",
    "        else:\n",
    "            # Add sentence to current chunk\n",
    "            current_chunk += \" \" + sentence if current_chunk else sentence\n",
    "    \n",
    "    # Don't forget the last chunk\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28892677",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now i want to chunk the pdf file \n",
    "# to chunk i first need to know what the content of the pdf is , so i need something to read the pdf \n",
    "import PyPDF2\n",
    "import os\n",
    "file_path=r'C:\\Users\\User\\Desktop\\Working_with_LLMS\\RAG\\Python For Dummies.pdf'\n",
    "file_name= os.path.basename(file_path)\n",
    "chunks=[]\n",
    "with open(file_path,'rb') as f:\n",
    "    pdf_reader=PyPDF2.PdfReader(f)\n",
    "    num_pages= len(pdf_reader.pages)\n",
    "\n",
    "    for page_num in range(num_pages):\n",
    "        page=pdf_reader.pages[page_num]\n",
    "        text= page.extract_text()\n",
    "\n",
    "        #chunk the page text\n",
    "        page_chunks=chunk_by_sentences(text,max_chunk_size=300)\n",
    "        for chunk in page_chunks:\n",
    "            chunks.append(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bc09058",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now that the pdf is chunked i want to save it inside my chromma collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0e25332",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\.cache\\chroma\\onnx_models\\all-MiniLM-L6-v2\\onnx.tar.gz: 100%|██████████| 79.3M/79.3M [02:19<00:00, 596kiB/s] \n"
     ]
    }
   ],
   "source": [
    "ids=[f\"doc_{i}\" for i in range(len(chunks))]\n",
    "collection.add(ids=ids,documents=chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c501c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=collection.query(query_texts=[\"What are integers\"],n_results=4,include=[\"embeddings\", \"documents\", \"metadatas\", \"distances\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "060a0ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is artificial intelligence?\n",
      "\n",
      "Top 3 results:\n",
      "\n",
      "After all, humans can use just one kind \n",
      "of number. To understand the need for multiple \n",
      "number types, you have to understand a little \n",
      "about how a computer works with numbers. An integer is stored in the computer as simply a \n",
      "series of bits that the computer reads directly.For example, the value 1 is a whole number, \n",
      "so it’s an integer. On the other hand, 1.0 isn’t a whole number; it has a deci -\n",
      "mal part to it, so it’s not an integer. Integers are represented by the int \n",
      "data type. As with storage boxes, variables have capacity limits.For now, all you really need to know is that integers support different \n",
      "numeric bases.86 Part II: Talking the Talk \n",
      "because each form requires a different kind of processing. The following sec -\n",
      "tions describe the integer, floating-point, and complex number classes of data \n",
      "types that Python supports. Integers\n",
      "Any whole number is an integer.\n"
     ]
    }
   ],
   "source": [
    "print(\"Query: What is artificial intelligence?\\n\")\n",
    "print(\"Top 3 results:\\n\")\n",
    "\n",
    "retrieved_text=\"\"\n",
    "for i, (doc, metadata, distance) in enumerate(zip(\n",
    "    results['documents'][0],\n",
    "    results['metadatas'][0],\n",
    "    results['distances'][0]\n",
    "), 1):\n",
    "    \n",
    "    retrieved_text += doc\n",
    "    # print(f\"{i}. (Distance: {distance:.4f})\")\n",
    "    # print(f\"   Document: {doc}\")\n",
    "    # print(f\"   Metadata: {metadata}\")\n",
    "    # print()\n",
    "print(retrieved_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f0bc713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"openai_key\")\n",
    "\n",
    "if not openai_api_key:\n",
    "    print(\"Warning: OpenAikey not found.Set it in env file\")\n",
    "\n",
    "else:\n",
    "    print(\"API key loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "806fbbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-CmI6T1e5YRHI58OKiJsJyPc8TTIo2', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Integers are whole numbers that are stored in a computer as a series of bits. They are represented by the int data type and support different numeric bases.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1765625369, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=31, prompt_tokens=277, total_tokens=308, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "#4. Generate response \n",
    "client=OpenAI(api_key=openai_api_key)\n",
    "question= \"what are integers\"\n",
    "prompt= f\"\"\"\n",
    "You are a helpful AI assistant. Answer the user's question based on the context provided below.\n",
    "\n",
    "Important guidelines:\n",
    "- Use ONLY information from the context\n",
    "- If the answer is not in the context, say \"I don't have enough information to answer this question.\"\n",
    "- Be concise and accurate\n",
    "\n",
    "Context:\n",
    "{retrieved_text}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "response= client.chat.completions.create(model=\"gpt-3.5-turbo\",messages=[{\"role\":\"user\",\"content\":prompt}],temperature=0)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
